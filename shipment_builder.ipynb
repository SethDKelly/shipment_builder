{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mapp\u001b[0m/                    \u001b[01;34minstance\u001b[0m/                 requirements.txt\r\n",
      "bill_of_lading.py       notes_about_csv_file.txt  shipment_builder.ipynb\r\n",
      "conda_requirements.yml  \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "\u001b[01;34mconfig\u001b[0m/                 README.md\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The items.csv file is structured as such:\n",
      "\n",
      "item_id\t  item_group  cubic_volume_ft\n",
      "10413\t  A\t          0.1\n",
      "10341\t  A\t          0.5\n",
      "10004\t  B\t          1.0\n",
      "80014\t  C\t          0.3\n",
      "20242\t  B\t          0.4\n",
      "…\t      …\t          …\n",
      "\n",
      "Each record in this csv file is representative of a single item.\n",
      "The item_id field is a unique identifier for the item, while the item_type and cubic_volume_ft fields are attributes of the item.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"notes_about_csv_file.txt\") as notes:\n",
    "    print(notes.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean_csv will need to have it's path changed once data/tmp/ is being implemented and build.items() used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv():\n",
    "    import pandas as pd\n",
    "\n",
    "    stock = pd.read_csv(\"app/data/items.csv\")\n",
    "\n",
    "    # Isolate the data to only the three necessary columns:\n",
    "        # 'item_id', 'item_group', 'cubic_volume_ft'\n",
    "    # Drop any NaN rows from the data\n",
    "  \n",
    "    return  (stock.loc[:,['item_id', 'item_group', 'cubic_volume_ft']]\n",
    "                  .dropna()\n",
    "            )\n",
    "    \n",
    "    '''\n",
    "    Future implementation will include functionality for: \n",
    "        Handling NaN values beyond just dropping them\n",
    "        Include column testing to ensure data types\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean should be renamed to extract_csv and then a pipeline module build. pipline.extract_csv, pipeline.transform() which will include any DataFrame transformations that need to happen prior to data processing (namely sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = clean_csv().sort_values(\"cubic_volume_ft\",\n",
    "                                ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 161 to 81\n",
      "Data columns (total 3 columns):\n",
      "item_id            200 non-null float64\n",
      "item_group         200 non-null object\n",
      "cubic_volume_ft    200 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_group</th>\n",
       "      <th>cubic_volume_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>8178.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>9667.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>4093.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1367.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2194.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_id item_group  cubic_volume_ft\n",
       "161   8178.0          C             0.11\n",
       "179   9667.0          B             0.11\n",
       "163   4093.0          C             0.12\n",
       "135   1367.0          D             0.12\n",
       "56    2194.0          C             0.13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_generator():\n",
    "    import random\n",
    "    import pandas as pd\n",
    "    return (pd.DataFrame(data = {'key': [random.randint(0,199) for x in range(random.randint(175,225))]})\n",
    "              .merge(clean_csv(), \n",
    "                     left_on='key', \n",
    "                     right_index=True)\n",
    "              .drop('key',\n",
    "                    axis = 1)\n",
    "              .reset_index(drop=True)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvTestData():    \n",
    "    # Builds anywhere from 150-250 rows of data that matches what comes from items.csv\n",
    "    # Creates random 'keys' that it merges with the stock data based on index\n",
    "    # returns the data as .csv's\n",
    "    \n",
    "    import random\n",
    "    import glob\n",
    "    import re\n",
    "    \n",
    "    # Checks to make sure there are no files\n",
    "    # If there are no files, file name should start with 1\n",
    "    if not sorted([int(re.sub(\"[^0-9]\", \"\", files)) for files in glob.glob(\"app/data/tmp/*.csv\")]):\n",
    "        count = '1'\n",
    "    else : # Start naming at whatever we're at +1\n",
    "        count = sorted([int(re.sub(\"[^0-9]\", \"\", files)) for files in glob.glob(\"app/data/tmp/*.csv\")])[-1] + 1\n",
    "\n",
    "    return (pd.DataFrame(data = {'key': [random.randint(0,199) for x in range(random.randint(150,250))]})\n",
    "              .merge(clean_csv(), \n",
    "                     left_on='key', \n",
    "                     right_index=True)\n",
    "              .drop('key',\n",
    "                    axis = 1)\n",
    "              .reset_index(drop=True)\n",
    "           ).to_csv(\"app/data/tmp/items\"+str(count)+\".csv\", \n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvTestData() # Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stockFromDataTMP():\n",
    "    \n",
    "    \"\"\"\n",
    "    Check app/data/tmp/ for any .csv data\n",
    "    Append all the data and return the result\n",
    "    result will be a single DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    import glob\n",
    "    \n",
    "    # It's nice to assume clean data, and to be right for once\n",
    "    \n",
    "    stock = pd.DataFrame()\n",
    "    for csv in glob.glob(\"app/data/tmp/*.csv\"):\n",
    "        stock = stock.append(pd.read_csv(csv))\n",
    "        \n",
    "    if stock.empty:\n",
    "        return stock\n",
    "    \n",
    "    else :\n",
    "        return (stock.sort_values('cubic_volume_ft')\n",
    "                     .reset_index(drop=True)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shipment_id():\n",
    "    import re\n",
    "    return int(re.sub(\"[^0-9]\", \"\", str(datetime.datetime.today()))[:17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future improvements will use arrays of idx and vol^3 zipped together for speed improvements.\n",
    "\n",
    "The result will be a dictionary of shipment_id and idx this will be able to be merged to result in final shipment.\n",
    "\n",
    "This implementation will have to be tested to prove speed improvements exist from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shipments(items) :\n",
    "    # Create a blank shipment sheet\n",
    "    shipment = {}\n",
    "    \n",
    "    while items.empty == False :\n",
    "\n",
    "        # Get the largest item by cubic volume and remove from items\n",
    "        bundle, items = items.tail(1), items.drop(items.tail(1).index, axis=0)\n",
    "        \n",
    "        # Filter the remaining items by what CAN still fit in the box\n",
    "        # Grab the index of the item and the item\n",
    "        for index, item in (items[items.cubic_volume_ft.values < (1.58 - bundle.cubic_volume_ft.values)]\n",
    "                            .sort_values(\"cubic_volume_ft\",\n",
    "                                         ascending=False)\n",
    "                           ).iterrows():\n",
    "            \n",
    "            # If there is no item in items that could fit into the bundle break out of the matrix\n",
    "            if (bundle.cubic_volume_ft.sum() + items.cubic_volume_ft.values.min()) > 1.58 :\n",
    "                break\n",
    "                \n",
    "            # If it fits it sits\n",
    "            # Add the item to the bundle\n",
    "            # Drop item from the items\n",
    "            elif (bundle.cubic_volume_ft.sum() + item.cubic_volume_ft) <= 1.58 :\n",
    "                item, items = (item, items.drop(index))\n",
    "                bundle = bundle.append(item)\n",
    "                \n",
    "        #Issue a shipment id to the bundle\n",
    "        shipment[generate_shipment_id()] = bundle\n",
    "\n",
    "    return shipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(items) :\n",
    "    # Create a blank shipment sheet\n",
    "    shipment = {'item_id':{},\n",
    "               'item_group':{},\n",
    "               'cubic_volume_ft':{}\n",
    "               }\n",
    "    \n",
    "    while items.empty == False :\n",
    "\n",
    "        # Get the largest item by cubic volume and remove from items\n",
    "        bundle, items = items.tail(1), items.drop(items.tail(1).index, axis=0)\n",
    "        \n",
    "        # Generate shipment_id\n",
    "        shipment_id = generate_shipment_id()\n",
    "\n",
    "        shipment['item_id'].update({(shipment_id, \n",
    "                                bundle.index[0]) : bundle.item_id.values[0]})\n",
    "\n",
    "        shipment['item_group'].update({(shipment_id, \n",
    "                                   bundle.index[0]) : bundle.item_group.values[0]})\n",
    "\n",
    "        shipment['cubic_volume_ft'].update({(shipment_id, \n",
    "                                        bundle.index[0]) : bundle.cubic_volume_ft.values[0]})\n",
    "\n",
    "        bundle_volume = shipment['cubic_volume_ft'][(shipment_id, \n",
    "                                                     bundle.index[0])]\n",
    "        \n",
    "        # Filter the remaining items by what CAN still fit in the box\n",
    "        # Grab the index of the item and the item\n",
    "        for index, item in (items[items.cubic_volume_ft.values < (1.58 - bundle_volume)]\n",
    "                            .sort_values(\"cubic_volume_ft\",\n",
    "                                         ascending=False)\n",
    "                           ).iterrows():\n",
    "            \n",
    "            # If there is no item in items that could fit into the bundle break out of the matrix\n",
    "            if (bundle_volume + items.cubic_volume_ft.values.min()) > 1.58 :\n",
    "                break\n",
    "                \n",
    "            # If it fits it sits\n",
    "            # Add the item to the bundle\n",
    "            # Drop item from the items\n",
    "            elif (bundle.cubic_volume_ft.sum() + item.cubic_volume_ft) <= 1.58 :\n",
    "                item, items = (item, items.drop(index))\n",
    "                shipment['item_id'].update({(shipment_id, \n",
    "                                        index) : item.item_id\n",
    "                                      })\n",
    "                shipment['item_group'].update({(shipment_id, \n",
    "                                           index) : item.item_group\n",
    "                                        })\n",
    "                shipment['cubic_volume_ft'].update({(shipment_id, \n",
    "                                                index) : item.cubic_volume_ft\n",
    "                                              })\n",
    "                \n",
    "                bundle_volume += shipment['cubic_volume_ft'][(shipment_id, index)]\n",
    "    return shipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = stockFromDataTMP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5179 entries, 0 to 5178\n",
      "Data columns (total 3 columns):\n",
      "item_id            5179 non-null float64\n",
      "item_group         5179 non-null object\n",
      "cubic_volume_ft    5179 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 121.5+ KB\n"
     ]
    }
   ],
   "source": [
    "items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.6 s ± 581 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "test_df = test(items)\n",
    "test_df = pd.DataFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 23s ± 951 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "shipment = shipments(items)\n",
    "shipment = pd.concat(shipment.values(), keys=shipment.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CREATE TABLE shipment (\n",
    "\tlevel_0 BIGINT, \n",
    "\tlevel_1 BIGINT, \n",
    "\titem_id FLOAT, \n",
    "\titem_group TEXT, \n",
    "\tcubic_volume_ft FLOAT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///app/data/db/shipment.db', echo=True, encoding='utf8\n",
    "shipment.to_sql('shipment', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"SELECT * FROM shipment\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('app/data/db/shipment.db')\n",
    "conn.execute(\"SELECT * FROM shipment\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(shipment):\n",
    "    \n",
    "    # Build initial summaries based on items and cubic volume in feet\n",
    "    data = {'Total Items' : len(shipment.item_id.values),\n",
    "            'Total Cubic Volume in Feet' : shipment.cubic_volume_ft.values.sum(),\n",
    "            'Total Item Groups' : len(shipment.item_group.unique())}\n",
    "    \n",
    "    # Check for shipment id and build additional shipment summaries\n",
    "    if shipment.index.get_level_values(0).any() :\n",
    "        shipment_id = shipment.index.get_level_values(0).unique()\n",
    "        data['Total shipments'] = len(shipment_id)\n",
    "        data['Shipment Item Ratio'] = round(len(shipment.item_id.values) / len(shipment_id),2)\n",
    "        data['Cubic Volume not Utilized'] = (1.58*len(shipment_id) - \n",
    "                                             shipment.cubic_volume_ft.values.sum())\n",
    "        data['Percent Cubic Volume not Utilized'] = round(((1.58 * len(shipment_id) - \n",
    "                                                            shipment.cubic_volume_ft.values.sum()) / \n",
    "                                                     shipment.cubic_volume_ft.values.sum()) * 100, 2)\n",
    "    # return resulting summary as a DataFrame\n",
    "    return (pd.DataFrame(data, \n",
    "                         index=['Details'])\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = summary(shipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(items):\n",
    "    if 'item_group' in items.keys() :\n",
    "        return items.item_group.unique()\n",
    "    else :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipments_filtered = {}\n",
    "for group in get_groups(items):\n",
    "    stock_filtered = items[items.item_group.values == group]\n",
    "    shipments_filtered[group] = shipments(stock_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
